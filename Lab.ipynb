{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqp4cTaNmJlMIE5mQRZMah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BecomeAllan/RNN/blob/main/Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdgNtVwJtz4b"
      },
      "source": [
        "# Laboratório\n",
        "\n",
        "## Implementações com RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4mmQSmK7UMI"
      },
      "source": [
        "# O que é uma RNN ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cxqL5BZ9Yhf"
      },
      "source": [
        "Uma Recurrent neural network (RNN) é uma arquitetura de Rede Neural que processa dados sequenciais, como palavra por palavra em uma frase ou informações através do tempo.\n",
        "\n",
        "Algo notável na RNN é a capacidade de processar sequências independente do tamanho do vetor de entrada, não precisando ter um tamanho fixo para poder rodar a rede. Por exemplo, uma única rede poderia processar frases com 3, 5, 10 ou mais palavras na mesma rede.\n",
        "\n",
        "Algumas aplicações são mostradas na imagem a seguir, no qual a *one to one* seria uma rede do tipo *FeedFoward*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-cbN7-q9SgL"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/BecomeAllan/RNN/main/images/Aquitetura.png)\n",
        "\n",
        "[Imagem retirada daqui](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB21kFiqdI-n"
      },
      "source": [
        "# Comportamento de uma RNN\n",
        "\n",
        "O comportamento de uma célula padrão de RNN é através de um loop, onde o $x_t$ é o input confome o tempo $t$ e está célula representada por $h_t$ transporta a informação para a próxima $h_{t+1}$ com a informação adicional para atualizar junto com o $x_{t+1}$.\n",
        "\n",
        "O comportamento de um estado de célula $h_t$ diz conforme a próxima informação vai ser processada, criando uma correlação do estado passado para o presente $t$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0zgJjW0HEYm"
      },
      "source": [
        "![Imagem](https://raw.githubusercontent.com/BecomeAllan/RNN/main/images/Esquelto.png)\n",
        "\n",
        "![Imagem](https://raw.githubusercontent.com/BecomeAllan/RNN/main/images/Feedfoward.png)\n",
        "\n",
        "\n",
        "\n",
        "[Imagens retiradas daqui](http://introtodeeplearning.com/slides/6S191_MIT_DeepLearning_L2.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUaIU0sSf2EI"
      },
      "source": [
        "## Pseudo-código de uma célula RNN\n",
        "\n",
        "Queremos que a célula de RNN complete a frase:\n",
        "+ \"I love recurrent neural\"\n",
        "\n",
        "prevendo na última interação a palavra:\n",
        "+ \"network\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMH3-P_Af10R"
      },
      "source": [
        "rnn_cell = RNN()\n",
        "\n",
        "# Inicial h_t\n",
        "hidden_state = [0,0,0,0]\n",
        "\n",
        "X_t = ['I', 'love', 'recurrent', 'neural'] ## input [x_1, x_2, x_3, x_4 ] output da Y_4 = ['network']\n",
        "\n",
        "for word in X_t:\n",
        "  y_hat, hidden_state = rnn_cell(word, hidden_state)\n",
        "\n",
        "# ['network']\n",
        "next_word_predict = y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27QE7eEijWXP"
      },
      "source": [
        "## Pseudo-código de uma célula RNN para amantes do KERAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8YMBGjqjqco",
        "outputId": "6be2a3a1-733d-4b2d-f5f3-59c358c231de"
      },
      "source": [
        "# Bibliotecas usadas\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "    \n",
        "dot = tf.matmul\n",
        "   \n",
        "# Criando a layer RNN\n",
        "class RNN_cell(keras.layers.Layer):\n",
        "  def __init__(self, rnn_units, input_dim, output_dim):\n",
        "    super(RNN_cell, self).__init__()\n",
        "\n",
        "    # Pesos\n",
        "    self.W_xh = self.add_weight(shape = (rnn_units, input_dim), initializer=\"random_normal\", dtype='float32')\n",
        "    self.W_hh = self.add_weight(shape = (rnn_units, rnn_units), initializer=\"random_normal\", dtype='float32')\n",
        "    self.W_hy = self.add_weight(shape = (output_dim, rnn_units), initializer=\"random_normal\", dtype='float32')\n",
        "\n",
        "    # Estado (h_0) inicial \n",
        "    self.h = tf.zeros([rnn_units, 1])\n",
        "  \n",
        "  def call(self, x):\n",
        "    # x -> h\n",
        "    # Atualiza o estado h_t\n",
        "    self.h = tf.tanh( dot(self.W_hh, self.h) + dot( self.W_xh, x))\n",
        "\n",
        "    # h -> y\n",
        "    # 'Dense'\n",
        "    predict = dot( self.W_hy, self.h)\n",
        "    return predict\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"W_xh\": self.W_xh.numpy(),\n",
        "            \"W_hh\": self.W_hh.numpy(),\n",
        "            \"W_hy\": self.W_hy.numpy(),\n",
        "            \"h\": self.h.numpy()}\n",
        "\n",
        "\n",
        "# Constantes\n",
        "RNN_UNITS = 2\n",
        "INPUT_DIM = 2\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "\n",
        "\n",
        "x = np.array([[1,3,5,7,9],\n",
        "              [2,4,6,8,10]], dtype='float32')\n",
        "print(f'Shape do input: {x.shape}')\n",
        "\n",
        "hidden = RNN_cell(RNN_UNITS, INPUT_DIM, OUTPUT_DIM)\n",
        "\n",
        "temp = x.shape[1]\n",
        "\n",
        "config = hidden.get_config()\n",
        "####\n",
        "print(f\"Pesos: \\n W_xh:\\n{config['W_xh']}\\n\\n W_hh:\\n{config['W_hh']}\\n\\n W_hy:\\n{config['W_hy']}\\n\\n h:\\n{config['h']}\")"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape do input: (2, 5)\n",
            "Pesos: \n",
            " W_xh:\n",
            "[[ 0.02845396  0.02858876]\n",
            " [-0.03540682 -0.04941677]]\n",
            "\n",
            " W_hh:\n",
            "[[-0.02695221 -0.05052906]\n",
            " [ 0.00677119  0.04593707]]\n",
            "\n",
            " W_hy:\n",
            "[[-0.03504531  0.02058718]]\n",
            "\n",
            " h:\n",
            "[[0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSZbN0zNO5p_",
        "outputId": "4e17e4a5-fd93-4a4a-d2ea-12ef1f5d37ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'rnn_units: {RNN_UNITS} | input_dim: {INPUT_DIM} | output_dim: {OUTPUT_DIM} |  Número de sequencias: {temp}')\n",
        "print(f\"Input: \\n {x}\\n\")\n",
        "for t in range(0, temp):\n",
        "  ht = hidden.get_config()\n",
        "  xt = x[:,t]\n",
        "  xt = xt.reshape((2,1))\n",
        "  y_hat = hidden(xt)\n",
        "  print(f\"> Tempo (t):{t} \\n> Valor do estado (h):\\n{ht['h']} \\n> Previu (y_hat): \\n{y_hat}\")\n",
        "  print('----\\n')\n",
        "\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn_units: 2 | input_dim: 2 | output_dim: 1 |  Número de sequencias: 5\n",
            "Input: \n",
            " [[ 1.  3.  5.  7.  9.]\n",
            " [ 2.  4.  6.  8. 10.]]\n",
            "\n",
            "> Tempo (t):0 \n",
            "> Valor do estado (h):\n",
            "[[0.]\n",
            " [0.]] \n",
            "> Previu (y_hat): \n",
            "[[-0.00574082]]\n",
            "----\n",
            "\n",
            "> Tempo (t):1 \n",
            "> Valor do estado (h):\n",
            "[[ 0.08542279]\n",
            " [-0.13343976]] \n",
            "> Previu (y_hat): \n",
            "[[-0.01323162]]\n",
            "----\n",
            "\n",
            "> Tempo (t):2 \n",
            "> Valor do estado (h):\n",
            "[[ 0.20136726]\n",
            " [-0.2999266 ]] \n",
            "> Previu (y_hat): \n",
            "[[-0.02024323]]\n",
            "----\n",
            "\n",
            "> Tempo (t):3 \n",
            "> Valor do estado (h):\n",
            "[[ 0.31269532]\n",
            " [-0.45099527]] \n",
            "> Previu (y_hat): \n",
            "[[-0.02649282]]\n",
            "----\n",
            "\n",
            "> Tempo (t):4 \n",
            "> Valor do estado (h):\n",
            "[[ 0.4155064]\n",
            " [-0.5795481]] \n",
            "> Previu (y_hat): \n",
            "[[-0.03188588]]\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEUHJIYAckOI"
      },
      "source": [
        "## Quantidade de  células (unidades) de RNN\n",
        "\n",
        "+ Veja pelo diagrama que não existe conexão entre as unidades de RNN mas apenas entre suas próprias células\n",
        "\n",
        "![Units](https://raw.githubusercontent.com/BecomeAllan/RNN/main/images/Units.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR_Qb7Li8uY7"
      },
      "source": [
        "# Quando usar uma RNN ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdZzGJUQlJ3i"
      },
      "source": [
        "## Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqnJPUzMrbNx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "\n",
        "!pip install unidecode\n",
        "from unidecode import unidecode\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-bCz5eclRam"
      },
      "source": [
        "## Tratamento de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAfxkvsat4A0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b37fa4c-1971-4b3f-ebe5-437304a82ef0"
      },
      "source": [
        "# Baixar dataset\n",
        "!gdown --id 15FhPHu7Hx6ul_k-EEBZwzpUWznK0gBR3\n",
        "\n",
        "!gdown --id 1Eq9oi3_1PuSZ5hoZS5M1A5pTMSyy3K_a\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15FhPHu7Hx6ul_k-EEBZwzpUWznK0gBR3\n",
            "To: /content/portuguese-poems.csv\n",
            "13.3MB [00:00, 80.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Eq9oi3_1PuSZ5hoZS5M1A5pTMSyy3K_a\n",
            "To: /content/Ethereum Historical Data.csv\n",
            "100% 130k/130k [00:00<00:00, 4.19MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlafdjkFuxw4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cad7e466-5a3f-4a7b-aaf0-19c552cd6a2d"
      },
      "source": [
        "# Data1\n",
        "df1 = pd.read_csv(\"portuguese-poems.csv\", encoding='UTF-8')\n",
        "\n",
        "# Data2\n",
        "df2 = pd.read_csv(\"Ethereum Historical Data.csv\", encoding='UTF-8')\n",
        "\n",
        "df1 = df1.dropna()\n",
        "df2 = df2.dropna()\n",
        "\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Author</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cecília Meireles</td>\n",
              "      <td>Retrato</td>\n",
              "      <td>Eu não tinha este rosto de hoje,\\r\\nAssim calm...</td>\n",
              "      <td>1018431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fernando Pessoa</td>\n",
              "      <td>Para ser grande, sê inteiro: nada</td>\n",
              "      <td>Para ser grande, sê inteiro: nada\\r\\nTeu exage...</td>\n",
              "      <td>1979413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Marina Colasanti</td>\n",
              "      <td>Eu sei, mas não devia</td>\n",
              "      <td>Eu sei que a gente se acostuma. Mas não devia....</td>\n",
              "      <td>301509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carlos Drummond de Andrade</td>\n",
              "      <td>Quadrilha</td>\n",
              "      <td>João amava Teresa que amava Raimundo\\r\\nque am...</td>\n",
              "      <td>1421206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eugénio de Andrade</td>\n",
              "      <td>É urgente o amor</td>\n",
              "      <td>É urgente o amor.\\r\\nÉ urgente um barco no mar...</td>\n",
              "      <td>621197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Author  ...    Views\n",
              "0            Cecília Meireles  ...  1018431\n",
              "1             Fernando Pessoa  ...  1979413\n",
              "2            Marina Colasanti  ...   301509\n",
              "3  Carlos Drummond de Andrade  ...  1421206\n",
              "4          Eugénio de Andrade  ...   621197\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pirlCPfptiF5"
      },
      "source": [
        "data = pd.DataFrame()\n",
        "\n",
        "\n",
        "Generative_inputs = '\\n\\n'.join(df1['Title'])\n",
        "\n",
        "\n",
        "df1['Title'] = df1['Title'].apply(unidecode).str.lower()\n",
        "df1['Content'] = df1['Content'].apply(unidecode).str.lower()\n",
        "\n",
        "# Criando os dados\n",
        "\n",
        "data['Econder_inputs'] = df1['Title']\n",
        "\n",
        "data['Decoder_inputs'] = df1['Content'].apply(lambda row: \"<BOS> \" + row[:-1])\n",
        "\n",
        "data['Decoder_targets'] = df1['Content'].apply(lambda row: row[1:] + \" <EOS>\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11wMYuGEYK-v"
      },
      "source": [
        "# Treina os Tokens - Encoder -\n",
        "tokenizer_Encoder = Tokenizer(char_level=True, lower=False)\n",
        "\n",
        "tokenizer_Encoder.fit_on_texts(data['Econder_inputs'])\n",
        "\n",
        "dictionary_Encoder = tokenizer_Encoder.word_index\n",
        "\n",
        "e = tokenizer_Encoder.texts_to_sequences(data['Econder_inputs'][0:1])\n",
        "e_text = tokenizer_Encoder.sequences_to_texts(e)\n",
        "\n",
        "print(dictionary_Encoder)\n",
        "print(f'O input: {data[\"Econder_inputs\"][0:1]}')\n",
        "print(f'O Token do input: {e}')\n",
        "print(f'O decode do Token do input: {e_text}')\n",
        "\n",
        "data['Econder_inputs'] = tokenizer_Encoder.texts_to_sequences(data['Econder_inputs'])\n",
        "\n",
        "\n",
        "\n",
        "# Treina os Tokens - Decoders -\n",
        "\n",
        "\n",
        "VOCAB_SIZE_DECODER = 500\n",
        "\n",
        "\n",
        "tokenizer_Decoder = Tokenizer(char_level=False, lower=True, oov_token='<OOV>')\n",
        "\n",
        "\n",
        "tokenizer_Decoder.fit_on_texts(data['Decoder_inputs'])\n",
        "tokenizer_Decoder.fit_on_texts(data['Decoder_targets'])\n",
        "\n",
        "\n",
        "dictionary_Decoder = tokenizer_Decoder.word_index\n",
        "len(dictionary_Decoder)\n",
        "\n",
        "tokenizer_Decoder.num_words = VOCAB_SIZE_DECODER\n",
        "\n",
        "\n",
        "d = tokenizer_Decoder.texts_to_sequences(data['Decoder_inputs'][0:1])\n",
        "d_text = tokenizer_Decoder.sequences_to_texts(d)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(dictionary_Decoder)\n",
        "print(f'O input: {data[\"Decoder_inputs\"][0:1]}')\n",
        "print(f'O Token do input: {d}')\n",
        "print(f'O decode do Token do input: {d_text}')\n",
        "\n",
        "\n",
        "data['Decoder_inputs'] = tokenizer_Decoder.texts_to_sequences( data['Decoder_inputs'])\n",
        "\n",
        "data['Decoder_targets'] = tokenizer_Decoder.texts_to_sequences(data['Decoder_targets'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akrp1IGzah0n"
      },
      "source": [
        "# Seq-Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bos8pRQgaU09"
      },
      "source": [
        "# Treina os Tokens\n",
        "tokenizer1 = Tokenizer(char_level=True, lower=False)\n",
        "\n",
        "vocab = sorted(set(Generative_inputs))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "idx2char = np.array(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3eQMB7YG4CC"
      },
      "source": [
        "def vectorize_string(string):\n",
        "  vectorized_output = np.array([char2idx[char] for char in string])\n",
        "  return vectorized_output\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # the length of the vectorized songs string\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  # randomly choose the starting indices for the examples in the training batch\n",
        "  idx = np.random.choice(n-seq_length, batch_size)\n",
        "\n",
        "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
        "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
        "\n",
        "  # x_batch, y_batch provide the true inputs and targets for network training\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "\n",
        "\n",
        "X, Y = get_batch(vectorize_string(Generative_inputs), 30, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rxY8wc2eTJR"
      },
      "source": [
        "Model = keras.Sequential()\n",
        "\n",
        "Model.add(layers.Embedding(len(vocab), 250, batch_input_shape=[1000, None]))\n",
        "Model.add(layers.LSTM(100))\n",
        "Model.add(layers.Dense(len(vocab)))\n",
        "\n",
        "Model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-1),\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    metrics = keras.metrics.categorical_accuracy\n",
        ")\n",
        "\n",
        "Y.shape\n",
        "\n",
        "Model.fit(x= X,y=Y, epochs=100)\n",
        "\n",
        "Model(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43FCVoZxTx0x"
      },
      "source": [
        "# Seq2value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrFvsM7XT47k"
      },
      "source": [
        "df2.head()\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "Model = keras.Sequential()\n",
        "\n",
        "Model.add(layers.LSTM(64, input_shape=(None, 3), return_sequences=True))\n",
        "Model.add(layers.LSTM(64))\n",
        "Model.add(layers.Dense(10, activation=keras.activations.elu))\n",
        "Model.add(BatchNormalization())\n",
        "Model.add(layers.Dense(1, activation='linear'))\n",
        "\n",
        "Model.summary()\n",
        "\n",
        "df2.columns\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df2[[\"Open\",\"Low\", 'High']].to_numpy(), df2[['Price']].to_numpy(), test_size = 0.2)\n",
        "\n",
        "X_train[1]\n",
        "\n",
        "Model(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b06KTcSQGYDt"
      },
      "source": [
        "# Encode-Decode (Seq2Seq)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FviOrtB45y4"
      },
      "source": [
        "MAX_LENGTH_TITLE = 26\n",
        "MAX_LENGTH_POEM = 30\n",
        "\n",
        "\n",
        "\n",
        "data_Econder_inputs = pad_sequences(data['Econder_inputs'], maxlen=MAX_LENGTH_TITLE, padding='post', truncating='post')\n",
        "\n",
        "data_Decoder_inputs = pad_sequences(data['Decoder_inputs'], maxlen=MAX_LENGTH_POEM, padding='post', truncating='post')\n",
        "\n",
        "data_Decoder_targets = pad_sequences(data['Decoder_targets'], maxlen=MAX_LENGTH_POEM, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "Encoder_Train, Encoder_Test, _, _ = train_test_split(data_Econder_inputs, data_Decoder_inputs, test_size = 0.2, random_state=5)\n",
        "Decoder_Train, Decoder_Test, Target_Train, Target_Test  =  train_test_split(data_Decoder_inputs, data_Decoder_targets, test_size = 0.2, random_state=5)\n",
        "\n",
        "Target_Train = keras.utils.to_categorical(Target_Train, num_classes=VOCAB_SIZE_DECODER)\n",
        "Target_Test = keras.utils.to_categorical(Target_Test, num_classes=VOCAB_SIZE_DECODER)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OvEtyZy8jXy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d47ffe0f-74d8-4bee-d9c6-ada7997a1a6c"
      },
      "source": [
        "# The embedding dimension\n",
        "embedding_dim_Encoder = 60\n",
        "embedding_dim_Decoder =  300\n",
        "VOCAB_SIZE_ENCODER = VOCAB_SIZE_DECODER\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 100\n",
        "\n",
        "\n",
        "## Encoder\n",
        "encode_input = keras.Input(shape=(None,), name=\"title\")\n",
        "encode_features = layers.Embedding(VOCAB_SIZE_ENCODER, embedding_dim_Encoder)(encode_input) \n",
        "encoder = layers.LSTM(rnn_units, return_state=True, name = 'encode')\n",
        "encode_output, state_h, state_c = encoder(encode_features)\n",
        "\n",
        "# Estado da celula \n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "#layers.Bidirectional\n",
        "\n",
        "#layers.CuDNNLSTM\n",
        "\n",
        "## Decoder\n",
        "decode_input = keras.Input(shape=(None,), name=\"content\")\n",
        "decode_features = layers.Embedding(VOCAB_SIZE_DECODER, embedding_dim_Decoder)(decode_input)\n",
        "decode = layers.LSTM(rnn_units, return_state=True, return_sequences=True, name = 'decode')\n",
        "decode_out, _, _ = decode(decode_features, initial_state = encoder_state)\n",
        "decoder_outputs = layers.Dense(VOCAB_SIZE_DECODER, activation=\"softmax\")(decode_out)\n",
        "\n",
        "# Estado da celula \n",
        "\n",
        "\n",
        "model = keras.Model([encode_input, decode_input], decoder_outputs)\n",
        "model.summary()\n",
        "\n",
        "#keras.backend.clear_session()\n",
        "\n",
        "#keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)\n",
        "\n",
        "hist = model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2),\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = \"acc\"\n",
        ")\n",
        "\n",
        "#class CustomCallback(keras.callbacks.Callback):\n",
        "#  def on_epoch_end(self, epoch, logs=None):\n",
        "#    if 0 == epoch%1: \n",
        "#        print(f'Época: {epoch} \\n output:{logs[\"predict\"]}')\n",
        "        \n",
        "\n",
        "history = model.fit([Encoder_Train, Decoder_Train], Target_Train,\n",
        "          batch_size = 5000,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[keras.callbacks.EarlyStopping('loss', min_delta=0.1, patience=3, restore_best_weights=True)],\n",
        "          epochs=10, verbose=2)\n",
        "\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "title (InputLayer)              [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "content (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_57 (Embedding)        (None, None, 60)     18000       title[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_58 (Embedding)        (None, None, 300)    90000       content[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "encode (LSTM)                   [(None, 100), (None, 64400       embedding_57[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decode (LSTM)                   [(None, None, 100),  160400      embedding_58[0][0]               \n",
            "                                                                 encode[0][1]                     \n",
            "                                                                 encode[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, None, 300)    30300       decode[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 363,100\n",
            "Trainable params: 363,100\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff9a3461170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 - 16s - loss: 5.6659 - acc: 0.1302 - val_loss: 4.7715 - val_acc: 0.4190\n",
            "Epoch 2/10\n",
            "2/2 - 12s - loss: 4.4573 - acc: 0.4189 - val_loss: 3.3924 - val_acc: 0.4190\n",
            "Epoch 3/10\n",
            "2/2 - 12s - loss: 3.4001 - acc: 0.4186 - val_loss: 3.3534 - val_acc: 0.4190\n",
            "Epoch 4/10\n",
            "2/2 - 12s - loss: 3.3521 - acc: 0.4186 - val_loss: 3.3245 - val_acc: 0.4190\n",
            "Epoch 5/10\n",
            "2/2 - 12s - loss: 3.3218 - acc: 0.4186 - val_loss: 3.2718 - val_acc: 0.4190\n",
            "Epoch 6/10\n",
            "2/2 - 12s - loss: 3.2665 - acc: 0.4186 - val_loss: 3.2324 - val_acc: 0.4190\n",
            "Epoch 7/10\n",
            "2/2 - 12s - loss: 3.2317 - acc: 0.4186 - val_loss: 3.2057 - val_acc: 0.4209\n",
            "Epoch 8/10\n",
            "2/2 - 12s - loss: 3.2015 - acc: 0.4262 - val_loss: 3.1676 - val_acc: 0.4411\n",
            "Epoch 9/10\n",
            "2/2 - 12s - loss: 3.1640 - acc: 0.4423 - val_loss: 3.1435 - val_acc: 0.4430\n",
            "Epoch 10/10\n",
            "2/2 - 13s - loss: 3.1409 - acc: 0.4436 - val_loss: 3.1272 - val_acc: 0.4430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQMciqCLNjWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847cf0f8-9ec9-43f4-f453-6ac706de9afc"
      },
      "source": [
        "# Predições \n",
        "pred = model.predict([Encoder_Test, Decoder_Test])\n",
        "\n",
        "def deconder_as(pred, num):\n",
        "  \n",
        "  nums = [int(u) for u in (np.random.uniform(0, len(Encoder_Test), 3))]\n",
        "  \n",
        "  for i in nums:\n",
        "    print(i)\n",
        "    preds = tf.random.categorical(pred[i], num_samples=1).numpy()\n",
        "\n",
        "    enc = tokenizer_Encoder.sequences_to_texts(np.array([ [idx] for idx in tf.squeeze(Encoder_Test[(i):(i+1)])]))\n",
        "    res = tokenizer_Decoder.sequences_to_texts(preds)\n",
        "    tgt = tokenizer_Decoder.sequences_to_texts([[idx] for idx in Decoder_Test[i]])\n",
        "    print(f'Encode: \\n>{\"\".join(enc)}')\n",
        "    print(f'Previsto:  \\n>{\" \".join(res)}')\n",
        "    print(f'Real: \\n>{\" \".join(tgt)}' )\n",
        "    print('-------------------\\n')\n",
        "deconder_as(pred,3)\n",
        "\n",
        "\n",
        "#def generating(title, num_words):\n",
        "#  words = []\n",
        "#  # Encoded\n",
        "#  e_text = tokenizer_Encoder.texts_to_sequences(\"title\")\n",
        "#\n",
        "#  encode_output, state_h, state_c = Econder_model(e_text)\n",
        "#  encoder_state = [state_h, state_c]\n",
        "#\n",
        "#  # Decoded\n",
        "#  decode_input = keras.Input(shape=(None,), name=\"content\")\n",
        "#  decode_features = layers.Embedding(VOCAB_SIZE_DECODER, embedding_dim_Decoder)(decode_input)\n",
        "#  decode = layers.LSTM(rnn_units, return_state=True, return_sequences=True, name = 'decode')\n",
        "#  decode_out, state_h, state_c = decode(decode_features, initial_state = encoder_state)\n",
        "#\n",
        "#  decoder_state = [state_h, state_c]\n",
        "#\n",
        "#\n",
        "#  decoder_outputs = layers.Dense(VOCAB_SIZE_DECODER, activation=\"softmax\")(decode_out)\n",
        "#\n",
        "#\n",
        "#\n",
        "#  decoded_model = keras.Model(decode_input, decode_out)\n",
        "#  \n",
        "#  pred = Decoder_model()\n",
        "#\n",
        "#  words.append(decode_out)\n",
        "#  \n",
        "#  for word in range(num_words):\n",
        "#\n",
        "#    decode_out, state_h, state_c = decode(decode_features, initial_state = encoder_state)\n",
        "#\n",
        "#    decoder_state = [state_h, state_c]\n",
        "#\n",
        "#    words.append(decode_out)\n",
        "\n",
        "#    decoder_outputs = layers.Dense(VOCAB_SIZE_DECODER, activation=\"softmax\")(decode_out)\n",
        "#    decoded_model = keras.Model(decode_input, decode_out)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2888\n",
            "Encode: \n",
            ">barra de santos\n",
            "Previsto:  \n",
            ">sera quando que em luz estar janeiro pelas palavras ali hoje ja en outro nosso en ti que em outro <OOV> is aqui olhar nao azul oh es and vezes\n",
            "Real: \n",
            ">bos <OOV> \r <OOV> que o mar <OOV> <OOV> ou <OOV> \r em que as <OOV> vem <OOV> <OOV> a <OOV> do meio dia \r e a tarde <OOV> <OOV>\n",
            "-------------------\n",
            "\n",
            "1980\n",
            "Encode: \n",
            ">comer cu, chupar bocetatem\n",
            "Previsto:  \n",
            ">fora paulo los esta no fogo peito maos alem dia rosto com dois sol y and ao medo agua pela amor diz entao \r na pelas me amar in minhas\n",
            "Real: \n",
            ">bos <OOV> \r no <OOV> da <OOV> enquanto <OOV> <OOV> outros <OOV> entre a mulher e o <OOV> quem mais <OOV> tem <OOV> o <OOV> e uma <OOV> que nao\n",
            "-------------------\n",
            "\n",
            "1752\n",
            "Encode: \n",
            ">num zoologico de letras\n",
            "Previsto:  \n",
            ">the vao pode oh sao melhor olhos por ali los my outro tal esta todo ar sonho the pag desejo <OOV> no ser belo sob longe versos dor manha sob\n",
            "Real: \n",
            ">bos <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
            "-------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}